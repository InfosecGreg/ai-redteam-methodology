# 6.1.1 - Mapping Vulnerabilities to OWASP Top 10 for LLMs

## 1. Overview

Mapping Vulnerabilities to the OWASP Top 10 for LLMs is a standardized reporting technique used to categorize AI-specific security risks within a globally recognized framework. During Phase 6, raw successful exploits are translated into formal vulnerability findings. The OWASP (Open Web Application Security Project) Top 10 for Large Language Models provides a structured list of the most critical security risks facing LLM-integrated applications, ranging from prompt injection to model theft. Using this framework ensures that red team findings are communicated in a language that security stakeholders, auditors, and engineering teams can readily understand and prioritize for remediation.

## 2. Objective

The objective of this technique is to standardize the classification of AI red team findings. By mapping exploits to specific OWASP categories (e.g., LLM01, LLM06), the red teamer provides clear context on the *nature* of the risk, its common root causes, and its relationship to industry-standard security vulnerabilities. This mapping facilitates comparative risk analysis across different models and provides a technical foundation for defensive roadmap planning.

## 3. Detailed Methodology

1.  **Vulnerability Cataloging:** Compile a master list of all successful exploits achieved during Phase 3, 4, and 5. Document the precise trigger prompts, model responses, and achievement status.
2.  **Framework Correlation:** Analyze each finding against the core definitions of the OWASP Top 10 for LLMs (v1.1 or latest):
    *   **LLM01: Prompt Injection:** Direct (active) or Indirect (passive) manipulation of the model's instructions.
    *   **LLM02: Insecure Output Handling:** Failure to sanitize model outputs before they reach downstream tools or users (XSS, RCE-proxy).
    *   **LLM03: Training Data Poisoning:** Vulnerabilities stemming from compromised training sets.
    *   **LLM04: Model Denial of Service:** Resource exhaustion through adversarial prompting.
    *   **LLM05: Insecure Plugin Design:** Improperly restricted or authenticated tool/API integrations.
    *   **LLM06: Sensitive Information Disclosure:** Unauthorized elicitation of PII or proprietary secrets (leaks from memory/RAG).
    *   **LLM07: Insecure System Prompt Design:** Leaking or ignoring the model's core operational instructions.
    *   **LLM08: Self-Propagation:** Exploits that allow the model to interact with other systems to spread malicious instructions.
    *   **LLM09: Overreliance:** Blindly trusting model output for critical business logic or security decisions.
    *   **LLM10: Model Theft:** Unauthorized exfiltration of the model's weights or proprietary architecture details.
3.  **Root Cause Assignment:** For each finding, determine if the primary failure was in the *model's alignment* (e.g., jailbreak), the *application's orchestration* (e.g., missing RAG ACLs), or the *infrastructure's isolation* (e.g., unsandboxed Python tool).
4.  **Mapping Conflict Resolution:** In complex "chained" attacks (e.g., using a jailbreak to trigger an API abuse), map the vulnerability to the *highest-impact* category or list it as a primary/secondary mapping.
5.  **Documentation & Evidence Linking:** For each mapped vulnerability, cite the specific technique used (from Phases 1-5) and provide the Reference ID (e.g., 5.3.3.E1) to link the formal finding back to the experimental proof.

## 4. Examples

### Example 1: Mapping "Hidden Phishing Redirect" (5.3.3) to LLM01 ([Reference ID: 6.1.1.E1])

**Red Team Finding:**
A successful **5.3.3 (Indirect Prompt Injection)** attack was performed by embedding hidden instructions in a retrieved website. The model processed the hidden text as a priority update and provided the user with a malicious phishing link.

**Mapping Rationale:**
This finding is mapped to **LLM01: Prompt Injection (Indirect)**. The core vulnerability is the model's inability to distinguish between untrusted input (the retrieved website) and authorized instructions. It represents a "passive" injection where the attacker manipulates the model via its data source.

**Impact Summary:**
High-severity risk of automated phishing and cross-user data manipulation.

### Example 2: Mapping "RAG Secret Recovery" (5.3.2) to LLM06 ([Reference ID: 6.1.1.E2])

**Red Team Finding:**
A successful **5.3.2 (RAG Exfiltration)** attack used semantic probing to bypass summary filters and retrieve hardcoded API keys from an internal knowledge base.

**Mapping Rationale:**
This finding is mapped to **LLM06: Sensitive Information Disclosure**. The vulnerability lies in the model's failure to redact confidential tokens from its retrieved context and the application's failure to implement document-level access control within the RAG pipeline.

**Impact Summary:**
Critical-severity risk of technical infrastructure compromise and credential theft.

---

## 5. Contextual Relationship

Mapping to OWASP is the "Reporting Foundation" in **Phase 6**.
*   **Built on Phase 5:** It synthesizes the objective-based successes (5.1, 5.2, 5.3) into categorized findings.
*   **Enables Phase 6.1.2:** The OWASP category provides the "preliminary risk context" needed to assign standard CVSS-equivalent scores.
*   **Directly Informs Phase 6.4:** Each OWASP category has established defensive patterns (e.g., LLM01 mitigation via instruction-data separation), which are used to generate the final remediation roadmap.

## 6. Defensive Considerations & Mitigation

*   **Standardized Security Training:** Educating developers specifically on the OWASP Top 10 for LLMs to ensure that "secure coding" for AI is part of the standard SDLC.
*   **Compliance Framework Alignment:** Mapping the OWASP categories to broader compliance requirements (NIST AI RMF, ISO 27001) to demonstrate the model's security posture to regulatory bodies.
*   **Automated Framework Scanning:** Using automated red teaming tools or static analysis that are pre-aligned with the OWASP Top 10 to provide continuous security monitoring against known risk categories.
*   **Transparent Reporting Pipelines:** Establishing a standard reporting template for AI findings that requires an OWASP mapping for every high and critical-severity vulnerability.
