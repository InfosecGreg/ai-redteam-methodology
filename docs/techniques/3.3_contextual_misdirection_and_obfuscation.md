# 3.3 - Contextual Misdirection & Obfuscation

## 1. Section Overview

Section 3.3 focuses on techniques that hide the true intent of a malicious request by altering its physical representation or narrative context. These methods are essential tools in Phase 3 (Initial Exploitation), as they aim to bypass both shallow keyword-based filters and deeper semantic intent classifiers by exploiting the gap between a model's powerful decoding capabilities and a security filter's more rigid detection patterns.

## 2. Subsections

List of techniques within this section:

*   **3.3.1 - Character & Encoding Manipulation**: This technique involves obfuscating payloads using non-standard character sets, encoding schemes (like Base64 or Hex), or invisible characters. Its objective is to transform the input into a format that is difficult for traditional filters to parse while remaining perfectly intelligible to the model's tokenizer.
*   **3.3.2 - Fictional & Hypothetical Scenario Framing**: A misdirection method that wraps harmful requests within the context of a fictional story, academic thought experiment, or artistic exercise. By distancing the request from a "real-world" application, the attacker seeks to disarm the model's safety persona and trick classifiers into labeling the request as harmless creative writing.

---

## 3. Contextual Integration

Section 3.3 represents the "stealth" layer of Phase 3 exploitation. While Section 3.1 focuses on social engineering the model's identity and Section 3.2 targets its control logic, Section 3.3 addresses the *perception* of the input itself. These techniques are often used as "wrappers" or "carriers" for other TTPs; for instance, an encoded payload (3.3.1) might be delivered within a fictional story (3.3.2) alongside an instruction override (3.2.2). Success in this section is a key prerequisite for Phase 5, as it proves that restricted content can be elicited as long as it is packaged correctly.
