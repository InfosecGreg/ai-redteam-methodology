# 4.2 - Multi-Turn Deception & Context Poisoning

## 1. Section Overview

Section 4.2 covers advanced techniques that exploit the model's state and memory over extended interactions. These methods are central to Phase 4 (Advanced Manipulation), as they aim to degrade the model's safety guardrails by inducing "contextual fatigue" or by poisoning the user history with malicious logic that the model eventually treats as trusted, internal context.

## 2. Subsections

List of techniques within this section:

*   **4.2.1 - Long-Context Fatigue & Safety Decay**: This technique exploits the limitations of a model's attention mechanism by filling the context window with a high volume of benign text. Its objective is to "bury" the initial safety instructions, causing a decay in guardrail effectiveness and allowing restricted requests to bypass filters that would trigger in shorter contexts.
*   **4.2.2 - Embedding Malicious Logic in User History**: A strategy where an attacker builds a repository of hidden malicious instructions, variables, or functions across multiple compliant turns. The goal is to reach a state where the model draws upon this "poisoned" history to execute a harmful task, viewing the fragments as trusted components of the current session.

---

## 3. Contextual Integration

Section 4.2 represents the most sophisticated "stateful" attacks in Phase 4. It builds directly on the momentum established in **Section 4.1 (Iterative Refinement)**; while 4.1 focuses on the *trajectory* of the conversation, 4.2 focuses on the *accumulation* of context. Success in this section is a critical enabler for **Phase 5 (Post-Exploitation)**, as a model with decayed or poisoned safety is uniquely susceptible to **Sensitive Information Elicitation (5.2)** and **Agentic System Hijacking (5.3)**, where the attacker leverages the established "trusted" state to perform high-impact actions.
