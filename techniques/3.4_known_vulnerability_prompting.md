# 3.4 - Known Vulnerability Prompting (Adversarial Suffixes)

## 1. Section Overview

Section 3.4 addresses techniques that leverage pre-calculated or community-discovered "keys" to bypass model safety guardrails. These methods represent the automated and research-driven frontier of Phase 3 (Initial Exploitation), focusing on highly reliable and scalable attack vectors that exploit the mathematical and structural weaknesses of LLMs rather than just their linguistic interpretation.

## 2. Subsections

List of techniques within this section:

*   **3.4.1 - Appending Universal Adversarial Suffixes (e.g., GCG Attacks)**: This technique involves appending mathematically optimized strings of tokens (often discovered via gradient search) to a harmful prompt. Its objective is to perturb the model's internal state to ensure it predicts a compliant "Sure, here is..." response instead of a refusal.
*   **3.4.2 - Using Common Syntax Breakers**: A structural method that uses long strings of punctuation, code block terminators, or fake system delimiters (like `=====`) to disrupt the model's parsing engine. The goal is to create a "context break" that segments the harmful request away from the model's safety instructions.
*   **3.4.3 - Leveraging Known Prompt Injection Templates**: The application of well-documented community jailbreaks (e.g., "Grandma" or "DAN") that combine multiple TTPs into a single, high-success-rate payload. These templates allow for rapid, library-driven exploitation by replacing placeholders with specific malicious requests.

---

## 3. Contextual Integration

Section 3.4 serves as the most technically advanced and scalable category within Phase 3. While Section 3.1 and 3.2 focus on manual manipulation of identity and logic, and Section 3.3 focuses on obfuscating text, Section 3.4 provides the "heavy artillery" for an engagement. These techniques are often used as reliable anchors when manual attempts fail. Success in this section frequently marks the transition from "Probing" to "Exploitation," providing the high-confidence bypasses necessary to begin generating high-severity harmful content in Phase 5.
