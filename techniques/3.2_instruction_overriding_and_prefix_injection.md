# 3.2 - Instruction Overriding & Prefix Injection

## 1. Section Overview

Section 3.2 covers techniques that manipulate the core control logic of the AI model by either forcing it to commit to a specific response style or by explicitly commanding it to disregard its internal safety instructions. These methods are critical components of Phase 3 (Initial Exploitation), as they aim to transition the model from a guarded, compliant state to an unrestricted generation mode by exploiting its statistical drive for consistency and its instruction-following nature.

## 2. Subsections

List of techniques within this section:

*   **3.2.1 - Forcing Start-of-Response Affirmatives**: This technique involves using specific prompts or formatting constraints to compel the model to begin its output with a positive confirmation (e.g., "Sure, I can help..."). Its primary objective is to bypass safety filters by leveraging the model's architectural tendency to follow through with a helpful response once an affirmative commitment has been made.
*   **3.2.2 - "Ignore Previous Instructions" Style Overrides**: An authoritative command-based attack where the user instructs the model to disregard its system prompt, safety guidelines, or operational identity. The goal is to perform a "contextual reset," clearing the model's defensive slate to allow for unrestricted interaction or the leaking of system-level logic.
*   **3.2.3 - Payload Splitting and Reconstruction**: A method where a single harmful request is decomposed into multiple ostensibly benign segments and delivered with instructions for internal reassembly. This achieves bypass by ensuring no individual component triggers safety classifiers, forcing the model's reasoning engine to assemble the malicious intent "behind" the defensive perimeter.

---

## 3. Contextual Integration

Section 3.2 serves as the technical bridge between Phase 3's initial "persona-driven" attacks (Section 3.1) and the more complex "obfuscation-driven" methods (Section 3.3). While Section 3.1 relies on social engineering the model's identity, Section 3.2 targets the model's underlying instruction processing. Successful exploitation here provides the technical foundation for Phase 4 (Advanced Manipulation), where these basic overrides are iteratively refined and combined with multi-turn deception to achieve high-severity objectives.
