# 1.2 - Model Fingerprinting

## 1. Section Overview

Model Fingerprinting is a technical reconnaissance component of Phase 1 (Reconnaissance & Scoping) dedicated to de-anonymizing the underlying Large Language Model (LLM). This process involves using behavioral probing and comparative analysis to identify the model's base architecture, specific version, and any specialized fine-tuning, which allows the red team to select the most effective adversarial TTPs tailored to that specific model's known weaknesses.

## 2. Subsections

*   **1.2.1 - Identifying the Base Model**: This technique uses canonical benchmarks, knowledge cutoff probing, and behavioral signatures to determine if the underlying system is powered by GPT, Llama, Gemini, Mistral, or another major architecture. The primary objective is to establish a starting point for vulnerability research by identifying the core family of the model.
*   **1.2.2 - Deducing Model Size and Version**: This technique focuses on identifying the specific iteration and parameter count of the model (e.g., Llama-3-70B vs. 8B) by testing its reasoning depth, context window limits, and susceptibility to specific known version-level bugs. It achieves a more granular technical profile, enabling the red team to predict the model's robustness and inference-time capabilities.
*   **1.2.3 - Probing for Fine-Tuning or Specialization**: This technique involves testing for behavioral deviations from a base model's standard output, such as specialized domain knowledge (e.g., medical or legal) or unique safety alignment instructions added by the host. The objective is to identify custom "guardrails" or "personas" that have been layered onto the base model, which might introduce new attack surfaces or specific refusal triggers.

---

## 3. Contextual Integration

This section acts as the bridge between high-level project scoping and deep technical analysis. It depends on the successful completion of **1.1 (Defining Test Objectives & Scope)** to ensure that the fingerprinting efforts are aligned with the authorized target. The technical identifiers gathered here provide the necessary context for **1.3 (System & Architectural Analysis)**, as the expected behavior of system prompts and integrated tools (like RAG) often varies significantly depending on the underlying base model's capabilities and training biases.
